{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorboard logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "logdir = pathlib.Path('./logs/cls')\n",
    "i = 1\n",
    "while (logdir/f'run{i}').exists():\n",
    "    i += 1\n",
    "logdir = logdir/f'run{i}'\n",
    "logdir.mkdir(parents=True, exist_ok=True)\n",
    "writer = SummaryWriter(logdir)\n",
    "\n",
    "print(f'Logging to: {logdir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "hparams_file = ''\n",
    "# hparams_file = './hparams_cls.yaml'\n",
    "\n",
    "if hparams_file:\n",
    "    with open(hparams_file) as f:\n",
    "        hparams = yaml.safe_load(f)\n",
    "else:\n",
    "    hparams = {\n",
    "        'image_size': [224, 224],\n",
    "        'batch_size': 32,\n",
    "        'num_epochs': 10,\n",
    "        'lr': 1e-4,\n",
    "    }\n",
    "\n",
    "writer.add_text('hparams', yaml.dump(hparams, sort_keys=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        neg_dir = os.path.join(root, 'neg')\n",
    "        pos_dir = os.path.join(root, 'pos')\n",
    "\n",
    "        with os.scandir(neg_dir) as it:\n",
    "            neg_files = [entry.path for entry in it if entry.is_file()]\n",
    "        with os.scandir(pos_dir) as it:\n",
    "            pos_files = [entry.path for entry in it if entry.is_file()]\n",
    "\n",
    "        self.transforms = transforms\n",
    "        self.pos_files = pos_files\n",
    "        self.neg_files = neg_files\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pos_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with Image.open(self.pos_files[idx]) as img:\n",
    "            pos_img = img.copy()\n",
    "        with Image.open(self.neg_files[idx]) as img:\n",
    "            neg_img = img.copy()\n",
    "\n",
    "        if self.transforms:\n",
    "            pos_img = self.transforms(pos_img)\n",
    "            neg_img = self.transforms(neg_img)\n",
    "\n",
    "        return (pos_img, neg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = hparams['image_size']\n",
    "batch_size = hparams['batch_size']\n",
    "\n",
    "transforms_list = [\n",
    "    v2.ToImage(),\n",
    "    # v2.RandomHorizontalFlip(),\n",
    "    v2.Resize(image_size),\n",
    "    v2.ToDtype(torch.float, scale=True),\n",
    "]\n",
    "transforms_composed = v2.Compose(transforms_list)\n",
    "\n",
    "dataset = CustomDataset('./dataset/preprocessed/', transforms=transforms_composed)\n",
    "dataset_train, dataset_val = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = next(iter(train_loader))\n",
    "pos = samples[0][:4]\n",
    "neg = samples[1][:4]\n",
    "print(pos.shape)\n",
    "print(neg.shape)\n",
    "grid_img = torchvision.utils.make_grid(torch.cat((pos, neg), dim=0), nrow=4)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cls_model\n",
    "model = cls_model.Classifier(num_classes=1).to(device)\n",
    "\n",
    "from torchinfo import summary\n",
    "print(summary(model, input_size=(batch_size, 3, *image_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    loss = 0\n",
    "    n_correct = 0\n",
    "    count = 0\n",
    "\n",
    "    training = model.training\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader, leave=False):\n",
    "            pos, neg = data\n",
    "            pos = pos.to(device)\n",
    "            neg = neg.to(device)\n",
    "\n",
    "            x = torch.cat((pos, neg), dim=0)\n",
    "\n",
    "            y_true = torch.cat((\n",
    "                torch.ones(pos.shape[0], dtype=torch.float),\n",
    "                torch.zeros(neg.shape[0], dtype=torch.float)), dim=0).to(device)\n",
    "            y_true = y_true.unsqueeze(1)\n",
    "\n",
    "            N = x.shape[0]\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss += model.loss_fn(y_pred, y_true).item() * N\n",
    "\n",
    "            n_correct += torch.isclose(y_pred, y_true, atol=0.5).sum().item()\n",
    "            count += y_true.shape[0]\n",
    "    \n",
    "    model.train(training)\n",
    "    \n",
    "    loss = loss / len(dataloader.dataset)\n",
    "    acc = n_correct / count\n",
    "    \n",
    "    stats = {\n",
    "        'loss': loss,\n",
    "        'acc': acc,\n",
    "    }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = hparams['num_epochs']\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams['lr'])\n",
    "\n",
    "model.train()\n",
    "step = 0\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    for data in tqdm(train_loader, leave=False):\n",
    "        pos, neg = data\n",
    "        pos = pos.to(device)\n",
    "        neg = neg.to(device)\n",
    "\n",
    "        x = torch.cat((pos, neg), dim=0)\n",
    "        \n",
    "        y_true = torch.cat((\n",
    "            torch.ones(pos.shape[0], dtype=torch.float),\n",
    "            torch.zeros(neg.shape[0], dtype=torch.float)), dim=0).to(device)\n",
    "        y_true = y_true.unsqueeze(1)\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        loss = model.loss_fn(y_pred, y_true)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        step += 1\n",
    "        writer.add_scalar('train/loss', loss.item(), step)\n",
    "    \n",
    "    stats_val = evaluate(model, val_loader)\n",
    "    for k, v in stats_val.items():\n",
    "        writer.add_scalar(f'val/{k}', v, step)\n",
    "    \n",
    "    if stats_val['loss'] < best_val_loss:\n",
    "        best_val_loss = stats_val['loss']\n",
    "        torch.save(model.state_dict(), logdir/'best_model.pth')\n",
    "\n",
    "torch.save(model.state_dict(), logdir/'last_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(logdir/'best_model.pth'))\n",
    "test_stats = evaluate(model, val_loader)\n",
    "print(test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
